import streamlit as st
import pandas as pd
import os
import glob
import re
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import platform
import altair as alt
from collections import Counter
import io
import random
import base64
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


# -----------------------
# ì„¤ì •
# -----------------------
data_folder = r"C:\Users\Owner\Documents\python\data"
logo_path = os.path.join(data_folder, "Kepco_logo.png")

# -----------------------
# ì‚¬ì´ë“œë°” ì‚¬ìš©ì ì „í™˜ UI
# -----------------------

# ----------------------------
# ì‚¬ì´ë“œë°” ì‚¬ìš©ì í”„ë¡œí•„ ë° ì—­í• ë³„ ì‹œê° êµ¬ì„±
# ----------------------------
import streamlit as st
import os
import base64
import streamlit as st
import os
import base64

# ğŸ“ ì‚¬ìš©ì ì´ë¯¸ì§€ ê²½ë¡œ
data_folder = r"C:\Users\Owner\Documents\python\data"

# ì‚¬ìš©ì ì •ë³´ ì •ì˜
users = [
    {"name": "ì¥ì§€ìš°", "role": "ë‹´ë‹¹ì", "image": "kim.jpg", "menu": ["ë°ì´í„° í™•ì¸", "ì ê²€í‘œ ë³´ê¸°"]},
    {"name": "ë‚˜ê¸ˆì˜", "role": "ì±…ì„ì", "image": "lee.jpg", "menu": ["ë°ì´í„° ì—…ë¡œë“œ", "í†µê³„ ì„¤ì •", "ì‹œìŠ¤í…œ ì„¤ì •"]},
]

if "selected_user_idx" not in st.session_state:
    st.session_state.selected_user_idx = 0

if st.sidebar.button("ì‚¬ìš©ì ì „í™˜"):
    st.session_state.selected_user_idx = (st.session_state.selected_user_idx + 1) % len(users)

current_user = users[st.session_state.selected_user_idx]
st.sidebar.markdown(f"âš™ï¸ **í˜„ì¬ ì„ íƒëœ ì‚¬ìš©ì:**<br>{current_user['name']} ({current_user['role']})", unsafe_allow_html=True)


# âœ… ìŠ¤íƒ€ì¼ ì‚½ì… (ë²„íŠ¼ì²˜ëŸ¼ ë³´ì´ê²Œ)
st.markdown("""
<style>
/* ğŸ”· ì‚¬ì´ë“œë°” ë°°ê²½ìƒ‰ ë³€ê²½ */
section[data-testid="stSidebar"] {
    background-color: #e6f0fa !important;
}
.user-pic {
    width: 48px;
    height: 48px;
    border-radius: 50%;
    background-size: cover;
    background-color: #ccc;
    margin-right: 10px;
    border: 2px solid #4a4a4a;
}
.menu-box {
    background-color: #eeeeee;
    padding: 0.5em 1em;
    border-radius: 8px;
    margin-bottom: 6px;
    font-size: 0.95rem;
    font-weight: 500;
    cursor: default;
}
.role-label {
    font-size: 13px;
    color: gray;
}
</style>
""", unsafe_allow_html=True)

# âœ… ë‘ ì‚¬ìš©ì ëª¨ë‘ í‘œì‹œ
st.sidebar.markdown("## ğŸ‘¤ ì‚¬ìš©ì ë©”ë‰´")

for user in users:
    name = user["name"]
    role = user["role"]
    menu = user["menu"]
    image_path = os.path.join(data_folder, user["image"])

    # base64 ì´ë¯¸ì§€ ì¸ì½”ë”©
    try:
        with open(image_path, "rb") as f:
            encoded_image = base64.b64encode(f.read()).decode()
    except FileNotFoundError:
        encoded_image = ""

    st.sidebar.markdown(f"""
    <div class='user-block'>
        <div class='user-pic' style="background-image:url('data:image/png;base64,{encoded_image}')"></div>
        <div>
            <strong>{name}</strong><br>
            <span class='role-label'>{role}</span>
        </div>
    </div>
    """, unsafe_allow_html=True)

    for item in menu:
        st.sidebar.markdown(f"<div class='menu-box'>{item}</div>", unsafe_allow_html=True)

    st.sidebar.markdown("---")



# -----------------------
# í•œê¸€ í°íŠ¸ ì„¤ì •
# -----------------------
if platform.system() == 'Windows':
    font_path = 'C:/Windows/Fonts/malgun.ttf'
elif platform.system() == 'Darwin':
    font_path = '/System/Library/Fonts/Supplemental/AppleGothic.ttf'
else:
    font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'

font_name = fm.FontProperties(fname=font_path).get_name()
plt.rc('font', family=font_name)
plt.rcParams['axes.unicode_minus'] = False

# -----------------------
# ìë™ ë¶„ë¥˜ ê¸°ì¤€ ì„¤ì •
# -----------------------
chapter_keywords = {
    "1ì¥ ì¡°ì§": ["ì¡°ì§", "ì±…ì„", "ê¶Œí•œ", "í˜‘ì¡°", "ë…ë¦½ì„±"],
    "2ì¥ í’ˆì§ˆë³´ì¦ê³„íš": ["í’ˆì§ˆë³´ì¦ê³„íš", "qa ê³„íš", "qap", "ê³„íš ìˆ˜ë¦½"],
    "3ì¥ ì„¤ê³„ê´€ë¦¬": ["ì„¤ê³„", "ë„ë©´ ê²€í† ", "ì„¤ê³„ ë³€ê²½"],
    "4ì¥ êµ¬ë§¤ë¬¸ì„œ ê´€ë¦¬": ["êµ¬ë§¤ë¬¸ì„œ", "êµ¬ë§¤ì„œë¥˜", "ìš”êµ¬ì‚¬í•­ ì „ë‹¬"],
    "5ì¥ ì§€ì‹œì„œ,ì ˆì°¨ì„œ ë° ë„ë©´": ["ì§€ì‹œì„œ", "ì ˆì°¨ì„œ", "ë„ë©´", "ì‘ì—…ì§€ì‹œ"],
    "6ì¥ ë¬¸ì„œê´€ë¦¬": ["ë¬¸ì„œ", "ê°œì •", "í†µì œ"],
    "7ì¥ êµ¬ë§¤í’ˆëª© ë° ìš©ì—­ì˜ ê´€ë¦¬": ["êµ¬ë§¤í’ˆëª©", "ìˆ˜ë ¹ê²€ì‚¬", "ìš©ì—­", "ì…ê³ "],
    "8ì¥ í’ˆëª©ì˜ ì‹ë³„ ë° ê´€ë¦¬": ["ì‹ë³„", "ì¶”ì ì„±", "ê³ ìœ ë²ˆí˜¸"],
    "9ì¥ ê³µì •ê´€ë¦¬": ["ê³µì •", "ì‘ì—…ê³µì •", "ê³µì •ë³€ê²½"],
    "10ì¥ ê²€ì‚¬": ["ê²€ì‚¬", "ìˆ˜ì…ê²€ì‚¬", "ê³µì •ê²€ì‚¬", "ìµœì¢…ê²€ì‚¬"],
    "11ì¥ ì‹œí—˜ê´€ë¦¬": ["ì‹œí—˜", "ì„±ëŠ¥ì‹œí—˜", "ê²€ì¦ì‹œí—˜"],
    "12ì¥ ì¸¡ì • ë° ì‹œí—˜ì¥ë¹„ì˜ ê´€ë¦¬": ["ì‹œí—˜ì¥ë¹„", "ê³„ì¸¡ê¸°", "êµì •", "ì¸¡ì •ê¸°"],
    "13ì¥ ì·¨ê¸‰, ì €ì¥ ë° ìš´ì†¡": ["ì·¨ê¸‰", "ë³´ê´€", "ìš´ì†¡", "ì €ì¥"],
    "14ì¥ ê²€ì‚¬, ì‹œí—˜ ë° ìš´ì „ìƒíƒœ": ["ìš´ì „ìƒíƒœ", "ìš´ì „ ì¤‘", "ì‹œìš´ì „", "ì‹œìš´ì „ ì¤‘ ì‹œí—˜"],
    "15ì¥ ë¶ˆì¼ì¹˜í’ˆëª©ì˜ ê´€ë¦¬": ["ë¶ˆì¼ì¹˜", "ë¶€ì í•©", "ê²°í•¨", "ì´íƒˆ"],
    "16ì¥ ì‹œì •ì¡°ì¹˜": ["ì‹œì •ì¡°ì¹˜", "ì¬ë°œ ë°©ì§€", "ê°œì„ ì¡°ì¹˜"],
    "17ì¥ í’ˆì§ˆë³´ì¦ê¸°ë¡": ["ê¸°ë¡", "í’ˆì§ˆê¸°ë¡", "ë³´ì¡´", "ê¸°ë¡ê´€ë¦¬"],
    "18ì¥ í’ˆì§ˆë³´ì¦ê°ì‚¬": ["ê°ì‚¬", "í’ˆì§ˆê°ì‚¬", "ë‚´ë¶€ê°ì‚¬"]
}

def classify_check_item(text):
    for chapter, keywords in chapter_keywords.items():
        for keyword in keywords:
            if re.search(keyword, text):
                return chapter
    return "ê¸°íƒ€"

def convert_to_check_item(text):
    text = text.strip()
    if len(text) < 5:
        return f"{text} ì—¬ë¶€ í™•ì¸."
    if text.endswith("í•˜ë‹¤") or text.endswith("í•©ë‹ˆë‹¤") or text.endswith("ë˜ì–´ì•¼ í•œë‹¤") or text.endswith("ë˜ì–´ì•¼ í•©ë‹ˆë‹¤"):
        base = re.sub(r'(í•˜ë‹¤|í•©ë‹ˆë‹¤|ë˜ì–´ì•¼ í•œë‹¤|ë˜ì–´ì•¼ í•©ë‹ˆë‹¤)$', '', text)
        return f"{base} ì—¬ë¶€ í™•ì¸."
    elif text.endswith("í•  ê²ƒ") or text.endswith("í•  ê²ƒì„"):
        base = re.sub(r'(í•  ê²ƒ|í•  ê²ƒì„)$', '', text)
        return f"{base} ì ê²€."
    else:
        return f"{text} ì—¬ë¶€ í™•ì¸."


# -----------------------
# CSS ìŠ¤íƒ€ì¼
# -----------------------
st.markdown("""
<style>
/* ì „ì²´ ë°°ê²½ ë° í°íŠ¸ */
body {
    background-color: #f0f2f5;
    font-family: 'Nanum Gothic', sans-serif;
    color: #2f2f2f;
}

/* ì¼ë°˜ ë²„íŠ¼ ìŠ¤íƒ€ì¼ - í¬ê¸° ì†Œí­ ì¦ê°€ */
.stButton > button {
    background-color: #4a4a4a;
    color: white;
    font-weight: 600;
    border-radius: 32px;
    padding: 0.9em 2em;
    margin-bottom: 0.7em;
    font-size: 1.1rem;
    box-shadow: 0 2px 6px rgba(0, 0, 0, 0.08);
    transition: background-color 0.3s ease, box-shadow 0.3s ease, transform 0.15s ease;
}

.stButton > button:hover {
    background-color: #2f2f2f;
    box-shadow: 0 4px 10px rgba(0, 0, 0, 0.15);
    transform: translateY(-1px);
    cursor: pointer;
}

/* ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ - í¬ê¸° ì†Œí­ ì¦ê°€ */
.stDownloadButton > button {
    background-color: #6c757d !important;
    color: white !important;
    font-weight: 600 !important;
    border-radius: 32px !important;
    padding: 0.85em 1.8em !important;
    font-size: 1.1rem !important;
    box-shadow: 0 2px 6px rgba(108, 117, 125, 0.12) !important;
    transition: background-color 0.3s ease, box-shadow 0.3s ease, transform 0.15s ease !important;
}

.stDownloadButton > button:hover {
    background-color: #5a6268 !important;
    box-shadow: 0 4px 10px rgba(90, 98, 104, 0.18) !important;
    transform: translateY(-1px);
    cursor: pointer;
}

/* í…Œì´ë¸” í—¤ë” */
thead tr th {
    background-color: #4a4a4a !important;
    color: white !important;
}

/* ìˆ˜í‰ì„  ìŠ¤íƒ€ì¼ */
hr {
    border: 1.5px solid #4a4a4a;
    margin: 1em 0;
}
</style>
""", unsafe_allow_html=True)
# -----------------------
# ì „ì—­ í•¨ìˆ˜ ì •ì˜
# -----------------------
def normalize_project_name(name):
    if pd.isna(name):
        return ""
    name = str(name).strip()
    name = name.replace("-", ",").replace("â€“", ",").replace("â€”", ",")
    name = re.sub(r'([ê°€-í£a-zA-Z])\s*([0-9])', r'\1 \2', name)
    name = name.replace("  ", " ")
    name = re.sub(r'\s*,\s*', ",", name)
    if re.search("ìƒˆìš¸.*(3.?4|3,4|3-4)", name):
        return "ìƒˆìš¸ 3,4"
    return name

def extract_ngrams(text, n=2):
    words = text.split()
    return [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]

def clean_text(text):
    text = str(text).strip()
    text = re.sub(r'\b(ë°|ê´€ë ¨|ì˜|ì—|ì—ì„œ|ìœ¼ë¡œ)\b', '', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def normalize_keyword(phrase):
    phrase = clean_text(phrase)
    replacements = {
        r'(ì¼ì¹˜ ì—¬ë¶€|ì—¬ë¶€ í™•ì¸|í™•ì¸ ì—¬ë¶€)': 'ì—¬ë¶€ í™•ì¸',
        r'(ê´€ë ¨ ìš”ê±´.*|ìš”ê±´.*ì¼ì¹˜)': 'ìš”ê±´ ê´€ë ¨',
        r'(ë°©ì§€ êµìœ¡|êµìœ¡ ë°|êµìœ¡ ê´€ë ¨)': 'êµìœ¡ ê´€ë ¨',
        r'(ëŒ€ìƒìœ¼ë¡œ.*|.*ëŒ€ìƒìœ¼ë¡œ)': 'ëŒ€ìƒ ì§€ì •',
        r'(ì¬ë°œ ë°©ì§€|ì¬ë°œ.*)': 'ì¬ë°œ ë°©ì§€',
        r'(ë‹´ë‹¹ì.*)': 'ë‹´ë‹¹ì ê´€ë ¨',
    }
    for pattern, replacement in replacements.items():
        if re.search(pattern, phrase):
            return replacement
    return phrase

def convert_to_check_item(text):
    text = str(text).strip()
    if len(text) < 5:
        return f"{text} ì—¬ë¶€ í™•ì¸."
    if text.endswith("í•˜ë‹¤") or text.endswith("í•©ë‹ˆë‹¤") or text.endswith("ë˜ì–´ì•¼ í•œë‹¤") or text.endswith("ë˜ì–´ì•¼ í•©ë‹ˆë‹¤"):
        base = re.sub(r'(í•˜ë‹¤|í•©ë‹ˆë‹¤|ë˜ì–´ì•¼ í•œë‹¤|ë˜ì–´ì•¼ í•©ë‹ˆë‹¤)$', '', text)
        return f"{base} ì—¬ë¶€ í™•ì¸."
    elif text.endswith("í•  ê²ƒ") or text.endswith("í•  ê²ƒì„"):
        base = re.sub(r'(í•  ê²ƒ|í•  ê²ƒì„)$', '', text)
        return f"{base} ì ê²€."
    else:
        return f"{text} ì—¬ë¶€ í™•ì¸."

def preprocess_excel(file):
    temp_df = pd.read_excel(file, nrows=1, header=None)
    if temp_df.iloc[0].isnull().all():
        df = pd.read_excel(file, header=1)
    else:
        df = pd.read_excel(file)

    year_col = [c for c in df.columns if "ë°œí–‰ì—°ë„" in str(c)]
    if year_col:
        year_col = year_col[0]
        df[year_col] = pd.to_numeric(df[year_col], errors="coerce")
        df = df[(df[year_col] >= 2020) & (df[year_col] <= 2024)]
        df["ì—°ë„"] = df[year_col]
    else:
        df["ì—°ë„"] = np.nan

    if "ë‚©í’ˆì‚¬ì—…ì†Œ" not in df.columns:
        df["ë‚©í’ˆì‚¬ì—…ì†Œ"] = "ìƒˆìš¸ 3,4"

    ë‚´ìš©_col = [c for c in df.columns if "ë‚´ìš©" in str(c)]
    if ë‚´ìš©_col:
        ë‚´ìš©_col = ë‚´ìš©_col[0]
        df = df[~df[ë‚´ìš©_col].astype(str).str.contains("ë³´ì•ˆ í•­ëª©", na=False)]
        df["ê¶Œê³ ì‚¬í•­"] = df[ë‚´ìš©_col]
    else:
        df["ê¶Œê³ ì‚¬í•­"] = ""

    df["ì§€ì ìœ í˜•"] = "ê°ì‚¬/ê²€ì‚¬"
    codes = [f"A{str(i).zfill(2)}" for i in range(1, 71)] + [f"C{str(i).zfill(2)}" for i in range(1, 16)]
    df["ìœ„ë°° ë‚´ìš©"] = [random.choice(codes) for _ in range(len(df))]
    df["ì¶œì²˜íŒŒì¼"] = file.name
    df["ì •ê·œí™”_ì‚¬ì—…ëª…"] = df["ë‚©í’ˆì‚¬ì—…ì†Œ"].apply(normalize_project_name)

    if "ë“±ë¡ì¼" in df.columns:
        df.loc[df["ì—°ë„"].isna(), "ì—°ë„"] = pd.to_datetime(df["ë“±ë¡ì¼"], errors="coerce").dt.year
    if "ê²€í† ì¼" in df.columns:
        df.loc[df["ì—°ë„"].isna(), "ì—°ë„"] = pd.to_datetime(df["ê²€í† ì¼"], errors="coerce").dt.year

    return df

# âš ï¸ ê²½ê³ : íŒŒì¼ ë¯¸ì—…ë¡œë“œ ì‹œ ê²½ê³  ë©”ì‹œì§€ ì¶”ê°€
uploaded_csvs = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type="csv", accept_multiple_files=True)
uploaded_excels = st.file_uploader("ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx", "xls"], accept_multiple_files=True)

df = None
if uploaded_csvs:
    csv_dfs = []
    for csv in uploaded_csvs:
        for enc in ["cp949", "utf-8", "euc-kr"]:
            try:
                temp_df = pd.read_csv(csv, encoding=enc)
                temp_df["ì¶œì²˜íŒŒì¼"] = csv.name
                csv_dfs.append(temp_df)
                break
            except:
                continue
    if csv_dfs:
        df = pd.concat(csv_dfs, ignore_index=True)

if uploaded_excels:
    excel_dfs = [preprocess_excel(excel) for excel in uploaded_excels]
    excel_df = pd.concat(excel_dfs, ignore_index=True)
    if df is not None:
        df = pd.concat([df, excel_df], ignore_index=True)
    else:
        df = excel_df

if not uploaded_csvs and not uploaded_excels:
    st.warning("ğŸ“‚ CSV ë˜ëŠ” ì—‘ì…€ íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

# -----------------------
# íŒŒì¼ ì—…ë¡œë“œ ë° ë³‘í•©
# -----------------------
st.title("ê°ì‚¬ í†µê³„ ë° ì ê²€í‘œ ì‹œìŠ¤í…œ")

uploaded_csvs = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type="csv", accept_multiple_files=True)
uploaded_excels = st.file_uploader("ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx", "xls"], accept_multiple_files=True)

df = None
if uploaded_csvs:
    csv_dfs = []
    for csv in uploaded_csvs:
        for enc in ["cp949", "utf-8", "euc-kr"]:
            try:
                temp_df = pd.read_csv(csv, encoding=enc)
                temp_df["ì¶œì²˜íŒŒì¼"] = csv.name
                csv_dfs.append(temp_df)
                break
            except:
                continue
    if csv_dfs:
        df = pd.concat(csv_dfs, ignore_index=True)

if uploaded_excels:
    excel_dfs = [preprocess_excel(excel) for excel in uploaded_excels]
    excel_df = pd.concat(excel_dfs, ignore_index=True)
    if df is not None:
        df = pd.concat([df, excel_df], ignore_index=True)
    else:
        df = excel_df

if df is not None:
    st.success(f"ğŸ“‚ ì´ {len(df)}ê±´ ë°ì´í„° ì²˜ë¦¬ë¨.")
    st.dataframe(df.head())


# -----------------------
# íƒ€ì´í‹€
# -----------------------
# ì¤‘ì•™ íƒ€ì´í‹€
st.markdown("""
<h1 style='
    text-align: center;
    color: #2f2f2f;
    font-family: "Nanum Gothic", sans-serif;
    font-size: 36px;
    margin-bottom: 0.2em;
'>
ì‚¬ì—…ë³„ ê°ì‚¬ í†µê³„ ë° ì ê²€í‘œ ìƒì„± ì‹œìŠ¤í…œ
</h1>
""", unsafe_allow_html=True)

st.markdown("<hr>", unsafe_allow_html=True)  # ìŠ¤íƒ€ì¼ì— ë§ëŠ” êµ¬ë¶„ì„ 


# -----------------------
# ì„¸ì…˜ ì´ˆê¸°í™”
# -----------------------
if 'selected_project' not in st.session_state:
    st.session_state.selected_project = None
if 'show_stats' not in st.session_state:
    st.session_state.show_stats = False
if 'show_checklist' not in st.session_state:
    st.session_state.show_checklist = False

# -----------------------
# ì‚¬ì—… ì„ íƒ
# -----------------------
st.markdown("## ì‚¬ì—… ì„ íƒ")
project_list = ["ìƒˆìš¸ 3,4", "ì‹ í•œìš¸ 3,4", "ì‹ ê³ ë¦¬ 5,6", "ê°€ë™ì›ì „", "CTRF", "UAE"]
cols = st.columns(4)
for i, proj in enumerate(project_list):
    if cols[i % 4].button(proj):
        st.session_state.selected_project = proj
        st.session_state.show_stats = False
        st.session_state.show_checklist = False

# -----------------------
# ê¸°ëŠ¥ ë²„íŠ¼
# -----------------------
if st.session_state.selected_project:
    st.markdown(f"### ì„ íƒí•œ ì‚¬ì—…: {st.session_state.selected_project}")
    col_btn1, col_btn2 = st.columns(2)
    with col_btn1:
        if st.button("í†µê³„ ë³´ê¸°"):
            st.session_state.show_stats = True
            st.session_state.show_checklist = False
    with col_btn2:
        if st.button("ê°ì‚¬ ì ê²€í‘œ ìƒì„±í•˜ê¸°"):
            st.session_state.show_stats = False
            st.session_state.show_checklist = True

# -----------------------
# í†µê³„ ì‹œê°í™”
# -----------------------

if st.session_state.show_stats:
    sub_df = df[df['ì •ê·œí™”_ì‚¬ì—…ëª…'] == st.session_state.selected_project]
    words = Counter()

    if 'ê¶Œê³ ì‚¬í•­' in sub_df.columns:
        for text in sub_df['ê¶Œê³ ì‚¬í•­'].dropna().astype(str):
            text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', ' ', text)
            text = re.sub(r'\s+', ' ', text.strip())
            for n in [2, 3]:
                ngrams = extract_ngrams(text, n)
                for gram in ngrams:
                    normalized = normalize_keyword(gram)
                    if len(normalized) >= 4:
                        words[normalized] += 1

    if 'ì§€ì ìœ í˜•' in sub_df.columns:
        st.markdown("#### ê°ì‚¬ ìœ í˜• ë¶„í¬")
        counts = sub_df['ì§€ì ìœ í˜•'].value_counts().reset_index(name='íšŸìˆ˜')
        counts.columns = ['ì§€ì ìœ í˜•', 'íšŸìˆ˜']
        chart = alt.Chart(counts).mark_bar().encode(
            x=alt.X('ì§€ì ìœ í˜•:N', sort='-y'),
            y='íšŸìˆ˜:Q'
        ).properties(width=500, height=300)
        st.altair_chart(chart, use_container_width=False)

    if 'ì—°ë„' in sub_df.columns and 'ì§€ì ìœ í˜•' in sub_df.columns:
        st.markdown("#### ì—°ë„ë³„ ê°ì‚¬ìœ í˜• ë¶„í¬")
        yearly = sub_df.groupby(['ì—°ë„', 'ì§€ì ìœ í˜•']).size().reset_index(name='íšŸìˆ˜')
        if not yearly.empty:
            chart = alt.Chart(yearly).mark_line(point=True).encode(
                x='ì—°ë„:O',
                y='íšŸìˆ˜:Q',
                color='ì§€ì ìœ í˜•:N'
            ).properties(width=500, height=300)
            st.altair_chart(chart, use_container_width=False)

    # ğŸ“Œ ìœ„ë°° ë‚´ìš© 2ì—´ êµ¬ì„±
    if 'ìœ„ë°° ë‚´ìš©' in sub_df.columns:
        st.markdown("### ìœ„ë°° ë‚´ìš© ë¶„ì„")
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### ìœ„ë°°ì‚¬í•­ ë¶„í¬")
            vc = sub_df['ìœ„ë°° ë‚´ìš©'].value_counts().nlargest(5)
            fig, ax = plt.subplots(figsize=(4, 4))
            ax.pie(vc, labels=vc.index, autopct='%1.1f%%', startangle=140, textprops={'fontsize': 8})
            ax.axis('equal')
            st.pyplot(fig)

        with col2:
            st.markdown("#### ìƒìœ„ 5ê°œ í•­ëª©")
            for i, (w, c) in enumerate(vc.items(), 1):
                st.markdown(f"{i}. {w} <span style='color:gray;'>({c}íšŒ)</span>", unsafe_allow_html=True)

    # ğŸ“Œ ê¶Œê³ ì‚¬í•­ 2ì—´ êµ¬ì„±
    if words:
        st.markdown("### ê¶Œê³ ì‚¬í•­ ë¶„ì„")
        col3, col4 = st.columns(2)

        with col3:
            st.markdown("#### í‚¤ì›Œë“œ ë¶„í¬")
            common = dict(words.most_common(10))
            fig, ax = plt.subplots(figsize=(5, 3))
            ax.bar(common.keys(), common.values(), color='#779ecb')
            ax.set_xticklabels(common.keys(), rotation=45, ha='right', fontsize=8)
            ax.tick_params(axis='y', labelsize=8)
            st.pyplot(fig)

        with col4:
            st.markdown("#### ìƒìœ„ 3ê°œ í‚¤ì›Œë“œ")
            for i, (w, c) in enumerate(words.most_common(3), 1):
                st.markdown(f"{i}. {w} <span style='color:gray;'>({c}íšŒ)</span>", unsafe_allow_html=True)

# -----------------------
# ê°ì‚¬ ì ê²€í‘œ ìƒì„± (ì—°ë„ë³„ TF-IDF ë§¤ì¹­, ìƒìœ„ 20ê°œ ê¶Œê³ ì‚¬í•­ë§Œ ì‚¬ìš©)
# -----------------------
if st.session_state.show_checklist:
    st.markdown("### ì—°ë„ë³„ ê°ì‚¬ ì ê²€í‘œ ë³´ê¸°")

    # âœ… ê°ì‚¬ì ê²€í‘œ DB íŒŒì¼ ì—…ë¡œë“œ
    uploaded_checklist_file = st.file_uploader("ê°ì‚¬ì ê²€í‘œ DB ì—…ë¡œë“œ", type=["xlsx"], key="checklist_db")
    checklist_db = None
    if uploaded_checklist_file:
        checklist_db = pd.read_excel(uploaded_checklist_file)[["ì¥", "ì ê²€í•­ëª©"]].dropna()
        st.success("âœ… ê°ì‚¬ì ê²€í‘œ DB íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

    # âœ… ì—°ë„ë³„ ë²„íŠ¼ ìƒì„±
    year_cols = st.columns(4)
    for i, year in enumerate(range(2021, 2025)):
        if year_cols[i % 4].button(f"{year}ë…„ ê°ì‚¬ì ê²€í‘œ"):

            if checklist_db is None:
                st.warning("âš ï¸ ë¨¼ì € ê°ì‚¬ì ê²€í‘œ DB íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
                continue

            # âœ… ê¸°ì¤€ ì—°ë„ ì´ì „(2020ë…„ ì´ìƒ ~ year-1ë…„ ì´í•˜)ì˜ ê¶Œê³ ì‚¬í•­ ì‚¬ìš©
            check_df = df[(df["ì—°ë„"] >= 2020) & (df["ì—°ë„"] < year)]

            if check_df.empty:
                st.warning(f"{year}ë…„ ì ê²€í‘œë¥¼ ìƒì„±í•  ê¶Œê³ ì‚¬í•­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue

            # âœ… ê¶Œê³ ì‚¬í•­ ìƒìœ„ 20ê°œ ì¶”ì¶œ
            from collections import Counter
            counter = Counter(check_df["ê¶Œê³ ì‚¬í•­"].dropna().astype(str))
            top_titles = [t for t, c in counter.most_common(20)]

            if not top_titles:
                st.warning(f"{year}ë…„ ì ê²€í‘œë¥¼ ìƒì„±í•  ê¶Œê³ ì‚¬í•­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue

            # âœ… TF-IDF ë§¤ì¹­
            from sklearn.feature_extraction.text import TfidfVectorizer
            from sklearn.metrics.pairwise import cosine_similarity

            vectorizer = TfidfVectorizer()
            tfidf = vectorizer.fit_transform(checklist_db["ì ê²€í•­ëª©"].astype(str).tolist() + top_titles)

            checklist_vecs = tfidf[:len(checklist_db)]
            title_vecs = tfidf[len(checklist_db):]

            results = []
            for i_kw, title in enumerate(top_titles):
                sims = cosine_similarity(title_vecs[i_kw], checklist_vecs)[0]
                best_idx = sims.argmax()
                results.append({
                    "ì¥": checklist_db.iloc[best_idx]["ì¥"],
                    "ì ê²€í•­ëª© ë° ìš”ê±´": checklist_db.iloc[best_idx]["ì ê²€í•­ëª©"],
                    "ê·¼ê±°": title,      # Streamlitì—ì„œë§Œ í‘œì‹œ
                    "ì ê²€ ê²°ê³¼": "",    # ì—‘ì…€ìš©
                    "ë¹„ê³ ": ""         # ì—‘ì…€ìš©
                })

            checklist_df = pd.DataFrame(results)

            # âœ… ì¥ ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            checklist_df["ì¥ë²ˆí˜¸"] = checklist_df["ì¥"].str.extract(r"(\d+)").astype(float)
            checklist_df = checklist_df.sort_values(by=["ì¥ë²ˆí˜¸"]).drop(columns=["ì¥ë²ˆí˜¸"])

            # âœ… Streamlit í™”ë©´ í‘œì‹œ (ê·¼ê±° ê°•ì¡°, ì¸ë±ìŠ¤ ì œê±°)
            display_df = checklist_df[["ì¥", "ì ê²€í•­ëª© ë° ìš”ê±´", "ê·¼ê±°"]].reset_index(drop=True)
            styled_df = display_df.style.applymap(
                lambda _: "color: white; background-color: #1f77b4; font-weight: bold;",
                subset=["ê·¼ê±°"]
            )

            st.markdown(
                f"""
                <h3 style="margin-bottom:0;">{year}ë…„ ê°ì‚¬ì ê²€í‘œ</h3>
                <p style="margin-top:0; font-size:14px; color:gray;">
                    ê¸°ì¤€: 2020ë…„ ~ {year-1}ë…„ ê¶Œê³ ì‚¬í•­ ìƒìœ„ 20ê°œ
                </p>
                """,
                unsafe_allow_html=True
            )

            st.dataframe(styled_df, hide_index=True)

            # âœ… ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
            excel_df = checklist_df[["ì¥", "ì ê²€í•­ëª© ë° ìš”ê±´", "ì ê²€ ê²°ê³¼", "ë¹„ê³ "]]

            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
                excel_df.to_excel(writer, index=False, sheet_name="ê°ì‚¬ì ê²€í‘œ")

            st.download_button(
                label="ì—‘ì…€ë¡œ ë‹¤ìš´ë¡œë“œ",
                data=buffer.getvalue(),
                file_name=f"{st.session_state.selected_project}_{year}ë…„_ê°ì‚¬ì ê²€í‘œ.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key=f"download_excel_{year}",
            )

# -----------------------
# í•˜ë‹¨ ê³ ì§€
# -----------------------
st.markdown("""
---
<p style='text-align:center; font-size:13px; color:gray;'>
âš ï¸ ë³¸ ì‹œìŠ¤í…œì€ ê°œë°œ ì¤‘ì´ë©°, í•œêµ­ìˆ˜ë ¥ì›ìë ¥ê³¼ í•œêµ­ì›ìë ¥ì•ˆì „ê¸°ìˆ ì›ì´ ì œê³µí•œ ê³µê³µë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.
</p>
""", unsafe_allow_html=True)

# -----------------------
# í•˜ë‹¨ ê³ ì • ë¡œê³  (í•­ìƒ í™”ë©´ í•˜ë‹¨ ìš°ì¸¡ ê³ ì •)
# -----------------------
import base64

if os.path.exists(logo_path):
    with open(logo_path, "rb") as image_file:
        encoded_logo = base64.b64encode(image_file.read()).decode()

    st.markdown(f"""
        <div style='position: fixed; bottom: 20px; right: 30px; z-index: 999;'>
            <img src='data:image/png;base64,{encoded_logo}' width='100'/>
        </div>
    """, unsafe_allow_html=True)